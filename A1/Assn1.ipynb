{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from more_itertools import unique_everseen\n",
    "import nltk\n",
    "from word2number import w2n\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_text_into_sentences(text):\n",
    "    '''\n",
    "    Args:\n",
    "        text - the text which needs to be broken into sentences.\n",
    "    Function:\n",
    "        Break the 'text' into sentences after replacing every newline character by a whitespace.\n",
    "    returns:\n",
    "        a list of sentences.\n",
    "    '''\n",
    "    text = text.replace('\\n', ' ')\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def break_sentence_into_words(sentence):\n",
    "    '''\n",
    "    Args:\n",
    "            sentence - a string.\n",
    "    Function:\n",
    "            Break the 'sentence' into words using word_tokenize\n",
    "            and then checking if the word contains atleast an alphanum\n",
    "            for it to be a valid word.\n",
    "    return:\n",
    "            a list of words.\n",
    "    '''\n",
    "    words = []\n",
    "    probable_words = word_tokenize(sentence)\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    for word in probable_words:\n",
    "        w = lemmatizer.lemmatize(word)\n",
    "        if len(re.findall(r'[a-z0-9]', w, re.I)) > 0:\n",
    "            words.append(w)\n",
    "\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_num(word):\n",
    "    '''\n",
    "    '''\n",
    "    if word.startswith('0'):\n",
    "        return word\n",
    "\n",
    "    try:\n",
    "        word = str(w2n.word_to_num(word))\n",
    "    except BaseException:\n",
    "        word = word\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_1(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Print the number of words and sentences contained in text.\n",
    "    '''\n",
    "    print(\"\\n\\nQ1 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    num_of_sentences = len(sentences)\n",
    "    words = []\n",
    "    num_of_words = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words.append(break_sentence_into_words(sentence))\n",
    "        num_of_words += len(words[-1])\n",
    "\n",
    "    print(\"Number of Sentences \\t:-\\t \", num_of_sentences)\n",
    "    print(\"Number of Words \\t:-\\t \", num_of_words, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_2(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Print the number of words starting with consonants and the number of words starting\n",
    "        with vowels in the file given as input.\n",
    "    '''\n",
    "    print(\"\\n\\nQ2 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    words = []\n",
    "    num_of_vowels = num_of_consonants = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words.extend(break_sentence_into_words(sentence))\n",
    "\n",
    "    for word in words:\n",
    "        if re.match('[a-z]', word, re.I) is not None:\n",
    "            if re.match('[aeiou]', word, re.I) is not None:\n",
    "                num_of_vowels += 1\n",
    "            else:\n",
    "                num_of_consonants += 1\n",
    "\n",
    "    print(\"Number of Words starting with a vowel \\t\\t:-\\t \", num_of_vowels)\n",
    "    print(\n",
    "        \"Number of Words starting with a consonant \\t:-\\t \",\n",
    "        num_of_consonants,\n",
    "        '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_3(text):\n",
    "    '''\n",
    "    Question:\n",
    "        List all the email ids in the file given as input.\n",
    "    Assumptions :\n",
    "        Broke the text into sentences as done in Q1.\n",
    "            ID starts with alphanum.\n",
    "            Only contain alphanum, !#$%&’*+-/=?^_{|}~ in prefix (part before @)\n",
    "            Prefix is of length atleast 1.\n",
    "            @ can be followed by only alphanum(no special characters).\n",
    "            only alphanum is expected before @.\n",
    "            Exaclty one @.\n",
    "            Atleast a dot after @.\n",
    "            no dot before @.\n",
    "            No consecutive dots in ID\n",
    "            Max length of ID is 64\n",
    "            Ends with alphanum.\n",
    "            Duplicate IDs are not printed and counted.\n",
    "            If a ID is invalid but if its substring is a valid ID then it is chosen.\n",
    "    '''\n",
    "    print(\"\\n\\nQ3 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    mail_id = []\n",
    "    for sentence in sentences:\n",
    "        mail_id.extend(\n",
    "            [\n",
    "                id for id in re.findall(\n",
    "                    r'\\b[a-zA-Z0-9][a-zA-Z0-9!#$%&’\\*\\+\\-/=?^_{\\|}~]*[a-zA-Z0-9]*@[a-zA-Z0-9][a-zA-Z0-9-]*\\.[a-zA-Z0-9\\.\\-]*[a-zA-Z0-9]\\b',\n",
    "                    sentence,\n",
    "                    re.I) if len(id) < 65 and \"..\" not in id])\n",
    "\n",
    "    mail_id = list(unique_everseen(mail_id))  # remove duplicates\n",
    "    print(\"Number of valid mail-IDs = \", len(mail_id), '\\n')\n",
    "\n",
    "    for i, id in enumerate(mail_id):\n",
    "        print(str(i + 1) + '.\\t', id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_4(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Print the sentences and number of sentences starting with a given word in an input file.\n",
    "    Assumption:\n",
    "        Case insensitive\n",
    "        if entered word is a sentence then we take the first word of it\n",
    "        numerical search allowed\n",
    "    '''\n",
    "    print(\"\\n\\nQ4 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    count = 0\n",
    "\n",
    "    word = input(\"Enter a word : \")\n",
    "    word = break_sentence_into_words(word)[0]\n",
    "    word = word.lower()\n",
    "    word = word_to_num(word)\n",
    "\n",
    "    print(\"\\nWord which will be searched in file (case-insensitive) \\t=\\t\", word, '\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = break_sentence_into_words(sentence)\n",
    "        if len(words) > 0 and word_to_num(words[0].lower()) == word:\n",
    "            count += 1\n",
    "            print(str(count) + '.\\t', sentence)\n",
    "\n",
    "    print(\"\\nNumber of sentences which starts with entered word \\\"\" +\n",
    "          str(word) + \"\\\"\\t\\t=\\t\\t \", count, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_5(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Print the sentences and number of sentences ending with a given word in an input file.\n",
    "    Assumption:\n",
    "        Case insensitive\n",
    "        if entered word is a sentence then we take the first word of it\n",
    "        numerical search allowed\n",
    "    '''\n",
    "    print(\"\\n\\nQ5 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    count = 0\n",
    "\n",
    "    word = input(\"Enter a word : \")\n",
    "    word = break_sentence_into_words(word)[0]\n",
    "    word = word.lower()\n",
    "    word = word_to_num(word)\n",
    "\n",
    "    print(\n",
    "        \"\\nWord which will be searched in file (case-insensitive) \\t=\\t\",\n",
    "        word,\n",
    "        '\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = break_sentence_into_words(sentence)\n",
    "        if len(words) > 0 and word_to_num(words[-1].lower()) == word:\n",
    "            count += 1\n",
    "            print(str(count) + '.\\t', sentence)\n",
    "\n",
    "    print(\"\\nNumber of sentences which ends with entered word \\\"\" +\n",
    "          str(word) + \"\\\"\\t\\t=\\t\\t \", count, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_6(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Given a word and a file as input, print the count of that word and sentences containing\n",
    "        that word in the input file.\n",
    "    Assumptions:\n",
    "        Numerical search allowed\n",
    "        Case-insensitive\n",
    "    '''\n",
    "    print(\"\\n\\nQ6 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    num_of_words = num_of_sentences = 0\n",
    "\n",
    "    word = input(\"Enter a word : \")\n",
    "    word = word.lower()\n",
    "    word = re.findall(r'\\w+', word)[0]\n",
    "    word = word_to_num(word)\n",
    "\n",
    "    print(\n",
    "        \"\\nWord which will be searched in file (case-insensitive) \\t=\\t\",\n",
    "        word,\n",
    "        '\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = break_sentence_into_words(sentence.lower())\n",
    "\n",
    "        for i in range(len(words)):\n",
    "            words[i] = word_to_num(words[i])\n",
    "\n",
    "        w = words.count(word)\n",
    "        if w > 0:\n",
    "            num_of_sentences += 1\n",
    "            num_of_words += w\n",
    "            print(w, \"times in the sentence --> \\n\" + sentence, \"\\n\\n\")\n",
    "\n",
    "    print(\"\\n\\nTotal count of words \\t\\t\\t\\t =\\t \", num_of_words)\n",
    "    print(\n",
    "        \"Number of sentences containing entered word \\t =\\t\\t\",\n",
    "        num_of_sentences,\n",
    "        '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_7(text):\n",
    "    '''\n",
    "    Question:\n",
    "        Given an input file, print the questions present, if any, in that file.\n",
    "    '''\n",
    "    print(\"\\n\\nQ7 : \\n\")\n",
    "\n",
    "    count = 0\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    for sentence in sentences:\n",
    "        if sentence.endswith('?'):\n",
    "            count += 1\n",
    "            print(str(count) + '.\\t', sentence)\n",
    "\n",
    "    print(\"\\nNumber of questions in given file \\t=\\t\", count, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_8(text):\n",
    "    '''\n",
    "    Question:\n",
    "        List the minutes and seconds mentioned in the date present in the file given as input.\n",
    "        For instance, for the date - Tue, 20 Apr 1993 17:51:16 GMT, the output should be 51\n",
    "        min, 16 sec)\n",
    "    '''\n",
    "    print(\"\\n\\nQ8 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        times = re.findall(r'\\b[01][0-9]:[0-5][0-9]:[0-5][0-9]\\b', sentence)\n",
    "        times.extend(re.findall(r'\\b2[0-3]:[0-5][0-9]:[0-5][0-9]\\b', sentence))\n",
    "\n",
    "        for time in times:\n",
    "\n",
    "            hr, mi, se = time.split(':')\n",
    "            print(time, \" --> \", mi, \"min\", se, \"sec\")\n",
    "\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_9(text):\n",
    "    '''\n",
    "    Question:\n",
    "        List the abbreviations present in a file given as input.\n",
    "    Assumption:\n",
    "        All uppercase.\n",
    "        Atleast length 2\n",
    "    '''\n",
    "    print(\"\\n\\nQ9 : \\n\")\n",
    "\n",
    "    sentences = break_text_into_sentences(text)\n",
    "    abbreviations = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        abbreviations.extend(re.findall(r'\\b[A-Z]{2,}\\b', sentence))\n",
    "\n",
    "    for i in abbreviations:\n",
    "        print(i)\n",
    "\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter File Name:20_newsgroups/rec.motorcycles/102616\n",
      "\n",
      "\n",
      "Q1 : \n",
      "\n",
      "Number of Sentences \t:-\t  356\n",
      "Number of Words \t:-\t  5583 \n",
      "\n",
      "\n",
      "\n",
      "Q2 : \n",
      "\n",
      "Number of Words starting with a vowel \t\t:-\t  1474\n",
      "Number of Words starting with a consonant \t:-\t  3927 \n",
      "\n",
      "\n",
      "\n",
      "Q3 : \n",
      "\n",
      "Number of valid mail-IDs =  13 \n",
      "\n",
      "1.\t blgardne@javelin.sim.es.com\n",
      "2.\t monthly_733561501@javelin.sim.es.com\n",
      "3.\t monthly_730969501@javelin.sim.es.com\n",
      "4.\t green@East.Sun.COM\n",
      "5.\t car377@druhi.att.com\n",
      "6.\t server@cerritos.edu\n",
      "7.\t Tanner@Cerritos.EDU\n",
      "8.\t arnie@magnus.acs.ohio-state.edu\n",
      "9.\t loki@Physics.McGill.CA\n",
      "10.\t rm-reviews@ftp.physics.mcgill.ca\n",
      "11.\t rm-reviews@physics.mcgill.ca\n",
      "12.\t username@host.subdomain.domain\n",
      "13.\t blaine_g@bix.com\n",
      "\n",
      "\n",
      "Q4 : \n",
      "\n",
      "Enter a word : i\n",
      "\n",
      "Word which will be searched in file (case-insensitive) \t=\t i \n",
      "\n",
      "1.\t I mean like I like riding my Yuka-yuka Fudgeo-Jammer      11 but what the heck.\n",
      "2.\t I love my BMW!\n",
      "3.\t I mean       even Villy Ogle flamed me for that!\n",
      "4.\t I guess you had to be there.\n",
      "5.\t I wasn't.)\n",
      "6.\t I wanted  to live a man's life, [Music slowly builds in background]  riding Nortons and Triumphs through the highest mountain passes  and the deepest valleys,  living the life of a Motorcyclist;  doing donuts and evading the police;  terrorizing old ladies and raping small children;  eating small dogs for tea (and large dogs for dinner).\n",
      "7.\t I ride my bike; I eat my lunch; I go to the lavat'ry.\n",
      "8.\t I ride real fast, My name is Chuck, It somehow seems to fit.\n",
      "9.\t I over-rate the worst bad f*ck, But like a real good sh*t.  Oh, I'm a Denizen and I'm okay!\n",
      "10.\t I flame all night and I ride all day.\n",
      "11.\t I wear high heels And bright pink shorts,  full leathers and a bra.\n",
      "12.\t I wish I rode a Harley,  just like my dear mama.\n",
      "13.\t I want!\"\n",
      "\n",
      "Number of sentences which starts with entered word \"i\"\t\t=\t\t  13 \n",
      "\n",
      "\n",
      "\n",
      "Q5 : \n",
      "\n",
      "Enter a word : day\n",
      "\n",
      "Word which will be searched in file (case-insensitive) \t=\t day \n",
      "\n",
      "1.\t Chuck [Sings to the tune of \"The Lumberjack Song\"]:  I'm a Denizen and I'm okay, I flame all night and I ride all day.\n",
      "2.\t [Hell's Angels Echo Chorus, surprisingly heavy on tenors]: He's a Denizen and he's okay, He flames all night and he rides all day.\n",
      "3.\t I flame all night and I ride all day.\n",
      "4.\t ~Newsgroups: rec.motorcycles ~From: Arnie Skurow <arnie@magnus.acs.ohio-state.edu> ~Subject: A letter from the Motorcycle Heritage Museum ~Date: Mon, 13 Apr 1992 11:04:58 GMT  I received the following letter from Jim Rogers, director of the Museum, the other day.\n",
      "\n",
      "Number of sentences which ends with entered word \"day\"\t\t=\t\t  4 \n",
      "\n",
      "\n",
      "\n",
      "Q6 : \n",
      "\n",
      "Enter a word : 3\n",
      "\n",
      "Word which will be searched in file (case-insensitive) \t=\t 3 \n",
      "\n",
      "1 times in the sentence --> \n",
      "by John Sloan\t\tDoD #11 The DoD Logo\t\t\tby Chuck Rogers\t\tDoD #3 The DoD  (this started it all)\tby The Denizen of Doom\tDoD #1 The DoD Anthem\t\t\tby Jonathan Quist\tDoD #94 Why you have to be killed\tby Blaine Gardner\tDoD #46 The rec.moto.photo.archive\tcourtesy of Bruce Tanner DoD #161 Patches? \n",
      "\n",
      "\n",
      "1 times in the sentence --> \n",
      "They discuss motorcycles and   motorcycling, beverages, cleaning fluids, baklavah, balaclava, caltrops,   helmets, anti-fog shields, spine protectors, aerodynamics, three-angle valve seats, bird hits, deer whistles, good restaurants, racing philosophy,  traffic laws, tickets, corrosion control, personalities, puns, double  entendres, culture, absence of culture, first rides and friendship. \n",
      "\n",
      "\n",
      "1 times in the sentence --> \n",
      "He who would become the holder of DoD membership #3 thought this was the funniest thing he'd seen in a while (being the sort that is pretty easily amused), so he claimed membership in the Denizens of Doom Motorcycle Club, and started signing his postings with his membership number. \n",
      "\n",
      "\n",
      "1 times in the sentence --> \n",
      "For example, you can send:  dir [dod] send [dod]bruce_tanner.gif send [dod]dodframe.ps  and you'll get back 5 mail messages; a directory listing, 3 uuencoded parts of bruce_tanner.gif, and the dodframe.ps file in ASCII. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Total count of words \t\t\t\t =\t  4\n",
      "Number of sentences containing entered word \t =\t\t 4 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q7 : \n",
      "\n",
      "1.\t Xref: cantaloupe.srv.cs.cmu.edu rec.motorcycles:102616 rec.motorcycles.dirt:3539 rec.motorcycles.harley:3023 rec.motorcycles.racing:1903 Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!ogicse!uwm.edu!cs.utexas.edu!uunet!orca!javelin.sim.es.com!blgardne From: blgardne@javelin.sim.es.com (Dances With Bikers) Newsgroups: rec.motorcycles,rec.motorcycles.dirt,rec.motorcycles.harley,rec.motorcycles.racing Subject: FAQ - What is the DoD?\n",
      "2.\t : javelin.DoD.monthly_733561501 Expires: Sun, 30 May 1993 07:05:01 GMT Sender: blgardne@javelin.sim.es.com (Blaine Gardner) Reply-To: blgardne@javelin.sim.es.com Followup-To: rec.motorcycles Organization: Evans & Sutherland Computer Corporation Lines: 849 Supersedes: <DoD.monthly_730969501@javelin.sim.es.com>  This is a periodic posting intended to answer the Frequently Asked Question: What is the DoD?\n",
      "3.\t ------------------------------------------------------------------------  Contents: How do I get a DoD number?\n",
      "4.\t by Blaine Gardner\tDoD #46 DoD \"Road Rider\" article\tby Bruce Tanner\t\tDoD #161 What is the DoD?\n",
      "5.\t by John Sloan\t\tDoD #11 The DoD Logo\t\t\tby Chuck Rogers\t\tDoD #3 The DoD  (this started it all)\tby The Denizen of Doom\tDoD #1 The DoD Anthem\t\t\tby Jonathan Quist\tDoD #94 Why you have to be killed\tby Blaine Gardner\tDoD #46 The rec.moto.photo.archive\tcourtesy of Bruce Tanner DoD #161 Patches?\n",
      "6.\t What patches?\n",
      "7.\t by Blaine Gardner\tDoD #46 Letter from the AMA museum      by Jim Rogers, Director DoD #395 The DoD Rules\t\t\tby consensus Other rec.moto resources\tby various Keepers\tDoD #misc The rec.moto.reviews.archive\tcourtesy of Loki Jorgenson DoD #1210 Updated stats & rides info\tby Ed Green (DoD #111) and others  ------------------------------------------------------------------------ \t\t\tHow do I get a DoD number?\n",
      "8.\t If the most Frequently Asked Question in rec.motorcycles is \"What is the DoD?\n",
      "9.\t So provide some information for the list, will ya?\n",
      "10.\t This is one of those questions in the same class as \"Why is the sky blue?\n",
      "11.\t and \"Why do women inevitably tell you that you're such a nice guy just before they dump you?\n",
      "12.\t Where will it end?\n",
      "13.\t Who knows?\n",
      "14.\t Will the DoD start sanctioning races, placing limits on the memory and clock rate of the on-board engine management computers?\n",
      "15.\t Will the DoD organize poker runs where each participant collects a hand of hardware and software reference cards?\n",
      "16.\t Will the DoD have a rally in which the attendees demand a terminal room and at least a 386-sized UNIX system?\n",
      "17.\t | |         )-:                :-(  O     | \\___// \\\\___/ |     T   )-:                :-(         \\     \\_/     /      O   )-:                :-(  F       \\___     ___/           )-:                :-(  L        \\ \\     / /        L   )-:                :-(  A         \\ vvvvv /         I   )-:                :-(  M         | (   ) |         V   )-:                :-(  E         | ^^^^^ |         E   )-:                 :-(  x        \\_______/        x   )-:                   :-(  x                       x   )-:                     :-(  x   rec.motorcycles   x   )-:                 :-(          USENET          )-:   ------------------------------------------------------------------------                        The DoD                by the Denizen of Doom    DoD #1   Welcome one and all to the flamingest, most wonderfullest newsgroup of all time: wreck.mudder-disciples or is it reak.mudder-disciples?\n",
      "18.\t Muck: I don't mean to preach, Terrible, but lighten up on the BMW      crowd eh?\n",
      "19.\t Terrible: Waddya going to do?\n",
      "20.\t Call in reinforcements???\n",
      "21.\t Let's see      what they say, eh?\n",
      "22.\t Terrible: B.T.???\n",
      "23.\t Terrible: What does BMW stand for anyway???\n",
      "24.\t Terrible: Hey, didn't you drop your BMW???\n",
      "25.\t Heritick: Heya Terrible, how's yer front to back bias?\n",
      "26.\t Terrible: Not bad, sold yer BMW?\n",
      "27.\t Buck: Nice tree Hooter, how'd ya get up there?\n",
      "28.\t Muck: What's a carbujector?\n",
      "29.\t Dill: Well, where do we race?\n",
      "30.\t Muck: Well, what about Mucho Guzlers and Lepurras?\n",
      "31.\t Muck: What about a Tridump?\n",
      "32.\t Terrible: Isn't that a chewing gum?\n",
      "33.\t Muck: Auggggg, Waddda about a Pluck-a-kity?\n",
      "34.\t Heritick: Heyya Muck, you tryin' to call up the demon rider himself?\n",
      "35.\t Muck: Why??\n",
      "36.\t : Wadddoes BMW stand for?\n",
      "37.\t : Oh, don't you mean BMW?\n",
      "38.\t Does this mean that all of the wreck.mudder-disciples will be riding mini-trikes?\n",
      "39.\t Are our arguing heros doomed?\n",
      "40.\t Sometime in the far distant past, a hapless newbie asked: \"What does DoD stand for?\n",
      "41.\t --  Bruce Tanner        (213) 860-2451 x 596    Tanner@Cerritos.EDU Cerritos College    Norwalk, CA             cerritos!tanner  **********************************************************  A couple of comments: Bruce has put quite a bit of effort into this, so why not drop him a note if you find the rec.moto.photo archive useful?\n",
      "42.\t ------------------------------------------------------------------------                        Patches?\n",
      "43.\t What patches?\n",
      "\n",
      "Number of questions in given file \t=\t 43 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q8 : \n",
      "\n",
      "07:05:04  -->  05 min 04 sec\n",
      "07:05:01  -->  05 min 01 sec\n",
      "11:04:58  -->  04 min 58 sec\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Q9 : \n",
      "\n",
      "FAQ\n",
      "FAQ\n",
      "ID\n",
      "GMT\n",
      "GMT\n",
      "VERSION\n",
      "AMA\n",
      "CA\n",
      "COM\n",
      "PS\n",
      "AMHF\n",
      "AMA\n",
      "AMA\n",
      "MTV\n",
      "VHS\n",
      "UNIX\n",
      "USENET\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "BMW\n",
      "WE\n",
      "KNOW\n",
      "WE\n",
      "KNOW\n",
      "WE\n",
      "KNOW\n",
      "WE\n",
      "KNOW\n",
      "BMW\n",
      "BMW\n",
      "GOOD\n",
      "BMW\n",
      "BMW\n",
      "BEAT\n",
      "ME\n",
      "WILHEM\n",
      "BMW\n",
      "NO\n",
      "CDC\n",
      "FAQ\n",
      "FAQ\n",
      "DIR\n",
      "SEND\n",
      "VMS\n",
      "DOD\n",
      "ASCII\n",
      "EDU\n",
      "CA\n",
      "AMA\n",
      "USENET\n",
      "AMA\n",
      "GMT\n",
      "AMHF\n",
      "FAQ\n",
      "TXT\n",
      "DOD\n",
      "LIST\n",
      "FAQ\n",
      "TXT\n",
      "CA\n",
      "FTP\n",
      "FTP\n",
      "NOTE\n",
      "NOTE\n",
      "PLEASE\n",
      "DO\n",
      "FTP\n",
      "RCR\n",
      "NH\n",
      "FL\n",
      "GPNDG\n",
      "SLC\n",
      "BIX\n",
      "SLC\n",
      "BIX\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    try:\n",
    "        file = open(input(\"Enter File Name:\"), \"r\")\n",
    "        text = file.read()  # type(text) = str)\n",
    "        file.close()\n",
    "    except BaseException:\n",
    "        print(\"File not found!!\")\n",
    "        sys.exit()\n",
    "\n",
    "    Q_1(text)\n",
    "    Q_2(text)\n",
    "    Q_3(text)\n",
    "    Q_4(text)\n",
    "    Q_5(text)\n",
    "    Q_6(text)\n",
    "    Q_7(text)\n",
    "    Q_8(text)\n",
    "    Q_9(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
